# üß† Apprentissage machine - Notes de cours

## Introduction

#### Historique
- 1943: Apparition du neurone artificiel (McCullock & Pitts).
- 1957: Perceptron (Rosenblatt)
- 1986: Backpropagation

#### Pourquoi ?
* Environnements inconnus
* Agent qui s'am√©liore avec l'exp√©rience

#### Applications
* Classification
* R√©gression/pr√©diction
* Clustering d'√©l√©ments similaires
* Renforcement
* R√©duction de dimensionnalit√© 

#### Learning element 
* El√©ment de performance (agent logique, bas√© sur l'utilit√©, exploration, ...)
* Composant fonctionnel (fonction d'√©valuation, de perception/action, de transitions, ...)
* Repr√©sentation (fonction lin√©aire avec poids, axiomes, r√©seau neuronal, ...)
* Feedback (victoire/d√©faite, r√©sultat, ...)

#### Types d'apprentissage
* **Supervis√©** : Exemples d'entr√©es et sorties disponible, l'objectif est d'obtenir une fonction qui associe l'un √† l'autre
* **Semi-supervis√©** : Les donn√©es d'apprentissage n'ont pas toujours une √©tiquette
* **Non-supervis√©** : Extraction des patterns dans les entr√©es sans direction sp√©cifique sans aucun feedback. Les r√©sultats sont √† interpr√©ter.
* **Renforcement** : Apprend en fonction des r√©compenses/punitions suite √† ses actions.

#### Repr√©sentation des donn√©es
S√©quence de valeurs r√©elles/ent√®res, matrices, vecteurs one-hot, bag-of-words ou tf-idf, ...

#### Flow typique du ML
1. **Preprocessing du dataset** : Feature extraction/scaling/selection, r√©duction de dimensionnalit√©, √©chantillonage, ...
2. **Apprentissage** : S√©lection du mod√®le, cross-validation, ...
3. **Evaluation** : M√©triques, optimisation des hyper-param√®tres, ...
4. **Pr√©diction**

## Vocabulaire et concepts

##### Epoch
Un passage complet sur l'ensemble de donn√©es.

##### Batch
Un sous-ensemble des donn√©es d'entra√Ænement lorsque celui-ci est trop volumineux pour √™tre utilis√© enti√®rement √† chaque fois.

Dans ce cas, on ajoute la notion d'*it√©ration* qui est le nombre de batches n√©cessaire pour compl√©ter une epoch

##### Feature scaling 
Normalise les donn√©es suivant une √©chelle (min-max, z-score, ...) pour √©viter les probl√®mes avec les mod√®les qui utilisent la notion de distance

##### Data imbalance 
Ph√©nom√®ne qui se produit lorsque la proportion d'exemples de chaque classe est tr√®s diff√©rente, ce qui tend √† favoriser les classes avec un grand nombre d'√©chantillons

##### Sous-apprentissage et sur-apprentissage
<img src="imgs/overfit.png" width="500">

##### Compromis biais-variance
Un haut biais permet un apprentissage g√©n√©ralement plus rapide et simple, mais procure de moins bonne performances sur les probl√®mes complexes (e.g. logistic regression, linear regression, ...).

Une haute variance permet d'impacter l'estimation de la fonction cible est d'√™tre plus r√©ceptif aux particularit√©s des donn√©es, ce qui est d√©sirable mais dans une certaine mesure afin d'√©viter l'overfitting (e.g. arbres de d√©cisions, knn, svm, ...).

C'est donc un compromis √† faire. On peut utiliser par exemple la r√©gularisation L2 (qui introduit un nouveau biais qui p√©naliser les valeurs extr√™mes de poids, √† condition d'avoir fait du feature scaling).

##### Minibatch
Stochastic gradient descent avec k > 1.

##### Backpropagation
Algorithme qui permet de calculer les d√©riv√©es partielles d'une fonction de co√ªts complexe (e.g. in√©gale et non convexe).

On part du vecteur d'erreur de la derni√®re couche, pour calculer l'erreur de la couche pr√©c√©dente qui est calcul√© √† partir de la d√©riv√©e de la fonction d'activation.

<img src="imgs/backpropagation.png" width="300">

##### Param√©trique et non-param√®trique
**Param√©trique** :
Estimation des param√®tres √† partir des donn√©es d'entra√Ænement. Le nombre de param√®tres est ind√©pendant du nombre de donn√©es (e.g. perceptron, SVM lin√©aire, logistic regression, ...).

L'avantage des mod√®les param√®triques est qu'ils sont g√©n√©ralement plus simple, l'apprentissage est rapide. ?√©anmoins ils sont souvent limit√©s aux probl√®mes simples.

**Non-param√©trique** :
Le nombre de param√®tres augmente avec la taille des donn√©es (e.g. DT, SVM, KNN, ...).

L'avantage des ces mod√®les est qu'ils sont g√©n√©ralement plus flexibles et puissant, mais ils sont plus lent √† entrainer et n√©cessite plus de donn√©es d'entrainement. Le risque de sur-apprentissage est √©galement plus √©lev√©.

G√©n√©ralement les m√©thodes non-param√©triques sont utiles lorsque l'on a beaucoup de donn√©es et aucune connaissance au pr√©alable, et qu'on veut √©viter de choisir les features.

## Classification simple

### Perceptron
<img src="imgs/perceptron_schema.png" width="500">

Le perceptron apprend les poids optimaux √† multiplier avec les entr√©es pour d√©terminer si le neurone s'active ou non. La fonction d'activation est celle de Heaviside (+1 si positif, -1 si n√©gatif). Il s'agit donc d'un outil de classification binaire.

<img src="imgs/perceptron.png" width="300">

A noter que w<sub>0</sub>x<sub>0</sub> = œë est appel√© le biais.

Le principe est le suivant : 
1. Les poids sont initalis√©s √† ‚âà 0
2. Pour chaque exemple d'entra√Ænement x<sup>(i)</sup> :
  1. On calcule la sortie estim√©e y<sup>(i)</sup>
  2. On met √† jour les poids w<sub>j</sub> += Œî w<sub>j</sub>

<img src="imgs/perceptron_weight.png" width="200">

*Œ∑* est un nombre entre 0 et 1 qui constitue le learning rate.

A noter que Œî w<sub>j</sub> est nul si la pr√©diction est correcte, donc le poids ne changera pas.

#### Remarques
Si le dataset n'est pas s√©parable lin√©airement, le perceptron bouclera √† l'infini.

Il est possible d'√©tendre le perceptron pour faire de la classification multi-classe par du *One-vs-All*, qui consiste √† cr√©er un classeur sp√©cialis√© dans la d√©tection d'une classe en particulier, puis de d√©terminer quel classeur est actif pour tel entr√©e.

### Adaptive linear neurons (Adaline)
<img src="imgs/adaline_schema.png" width="500">

Sur le m√™me principe que le perceptron, toutefois la fonction d'activation est lin√©raire, ce qui permet d'avoir des sorties continues plut√¥t que binaire. On rajoute parfois un *quantizer* pour la pr√©diction de classe.

On charche √† optimiser la fonction de co√ªts *Sum of Squared Errors* (SSE) entre les sorties et les vraies classes :

<img src="imgs/sse.png" width="200">

On utilise pour cela l'algorithme du gradient, notamment parce que J(w) est convexe mais aussi parce que c'est tr√®s rapide.

<img src="imgs/gradient.png" width="200">

Toutefois, on utilise g√©n√©ralement la *descente de gradient stochastique* (SGD) pour √©viter l'utilisation du dataset complet et acc√©lerer le temps de calcul. Dans ce cas, il faut veiller √† m√©langer le dataset pour obtenir des r√©sultats satisfaisants. Un learning rate adaptatif est particuli√®rement adapt√© avec le SGD. 

<img src="imgs/sgd.png" width="200">

#### Remarques
La mise √† jour des poids se fait sur le dataset en entier, √† l'inverse du perceptron o√π elle se fait exemple par exemple.

Le feature scaling permet d'acc√©lerer la descente du gradient.

Une valeur de learning rate *Œ∑* forte peut emp√™cher de converger (si le pas du gradient est trop √©lev√©) tandis qu'une valeur faible augmentera consid√©rablement le temps de calcul.

## Classification

### Logistic regression
<img src="imgs/logistic_schema.png" width="500">

La fonction d'activation est une sigmo√Øde (fonction logistique). Elle se base sur le principe du rapport des chances (odds ratio), c'est-√†-dire qu'une √©chantillon appartienne √† une certaine classe √©tant donn√© ses attributs.

La fonction de co√ªts est modifi√©e pour utilis√©e les logarithmes (Log-likelyhood) afin d'√©viter les underflow, en plus de trasformer les produits en somme, ce qui en soit les calculs plus faciles.

#### Remarques
La logistic regression est plus sensible aux outliers. Il s'agit √©galement d'un mod√®le simple qui est facile √† mettre en place et √† jour.

### Support vector machine (SVM)
<img src="imgs/svm_schema.png" width="500">

Le principe est de maximiser les marges (distance entre un hyperplan et les √©chantillons les plus proches de ce plan, a.k.a support vectors) entre les classes, dans le but d'√©viter l'overfitting et permettre une meilleure g√©n√©ralisation.

Un avantage du SVM est de pouvoir faire de la kernalisation. Il s'agit d'utiliser un noyau qui exploite des combinaisons non-lin√©aires et des attrinuts originaux en les projetant dans un espace √† plus haute dimension, dans laquelle ils deviennent potentiellement s√©parables (e.g. radial basis function kernel).

![Kernel](imgs/kernel.png)

#### Remarques
Les SVMs se concentrent principalement sur les √©chantillons √† la fronti√®re des classes. En pratique, les r√©sultats sont similaires ) la logistic regression.

Si on utilise un kernel, il est n√©cessaire d'entra√Æner le SVM dans la dimension sup√©rieure (logique) : il faut donc transformer toutes les entr√©es auparavant.

Le *gamma* du RBF kernel d√©termine l'influence des √©chantillons.

### Arbres de d√©cision
<img src="imgs/decision_tree_schema.png" width="500">

Le principe est d'exploiter les attributs de l'ensemble de donn√©es pour apprendre une s√©rie de "questions" pour inf√©rer les classes. Chaque noeud s√©pare les donn√©es qui permettent d'obtenir le plus grand gain d'information, et ce processus est r√©p√©t√© jusqu'√† ce que les feuilles soient *pures* (i.e. ne repr√©sentent qu'une seule classe).

On teste sur le dataset du parent *D<sub>p</sub>* la s√©paration selon l'attribut *f*, en fonction de l'impuret√© *I* et du nombre d'√©chantillons *N* du parent et des enfants :

<img src="imgs/info_gain.png" width="300">

L'impuret√© (qu'on cherche √† r√©duire), est calcul√©e selon l'entropie (elle-m√™me calcul√©e sur la proportion d'√©chantillons appartenant √† une certaine classe pour un certain noeud). C'est-√†-dire qu'elle sera nul si tous les √©chantillons sont dans la m√™me classe et maximale si tous les √©chantillons sont diff√©rents.

L'indice gini peut aussi √™tre utilis√© pour le calcul de l'impuret√©. Celui-ci est similaire √† l'entropie mais se base sur la probabilit√© d'erreur de classification.

#### Remarques
G√©n√©ralement, on fait une s√©paration binaire pour gagner en temps de calcul.

### Random forest
Il s'agit d'un ensemble d'arbres de d√©cisions (estimators), dont la classification se fait au vote majoritaire sur les k arbres.

Les performances sont g√©n√©ralement meilleures qu'avec un seul arbre.

### K-nearest neighbors (KNN)
<img src="imgs/knn.png" width="300">

Le principe est de se dire que les √©l√©ments proches les uns par rapport aux autres sont probablement de la m√™me classe.

L'algorithme est le suivant :
1. Choisis un nombre de voisins *k* et une mesure de distance
2. Trouver les *k* voisins les plus proches √† classer
3. Vote √† la majorit√© (pond√©r√©e ou non)

On utilise g√©n√©ralement une distance de minkowski.  

Un inconv√©nient majeur de cette m√©thode est que l'ensemble des exemples d'entrainement doit √™tre gard√© en m√©moire, et par cons√©quent les knn sont peu performants pour une dimensionnalit√© √©lev√©e.

## Ensemble learning
<img src="imgs/ensemble_learning.png" width="400">

On part du principe qu'un ensemble de classeur plus faibles performent mieux qu'un seul tr√®s bon classeur.

A partir d'un ensemble d'entra√Ænement, un certain nombre de classeurs sont produits (ceux-ci peuvent potentiellement √™tre diff√©rents algorithmes ou sous-ensemble d'entra√Ænement).

### Bagging (bootstrap aggregation)
<img src="imgs/bootstrap.png" width="400">

Le principe est d'utiliser diff√©rents sous-ensemble d'apprentissage (bootstrap) al√©atoire avec remise.

Chaque bootstrap est utilis√© pour entra√Æner un classeur.

Cela permet de r√©duire la variance, mais pas le biais. C'est pour cette raison qu'on utilise g√©n√©ralement des classeurs avec un biais faible (e.g. decision trees).

### Boosting
Le principe est de se focaliser sur les exemples difficiles √† classer.

L'algorithme est le suivant :
1. Tirer un sous-ensemble du dataset pour entrainer un premier classeur
2. Tirer un autre sous-ensemble du dataset et y rajouter 50% des exemples mal class√©s par le classeur pr√©c√©dent pour entrainer le suivant
3. R√©p√©ter l'op√©ration autant de fois que l'on veut
4. Faire un vote majoritaire

Th√©oriquement, cela permet de r√©duire √† la fois le biais et la variance contrairement au bagging. Toutefois, la variance est souvent √©lev√©e dans les algorithmes de boosting.

#### Adaboost
Il s'agit d'un mod√®le de boosting qui utilise le dataset complet et dont les √©chantillons sont pond√©r√©s √† chaque √©tape. Cela permet de construire un classeur qui apprend des erreurs pass√©es.

![Adaboost](imgs/adaboost.png)

Exemple : 
1. Maximisation de la fonction de co√ªts
2. Ajustement des poids, et entrainement d'un second classeur
3. Ajustement des poids, et entrainement d'un troisi√®me classeur
4. Vote majoritaire

## Text mining

### Repr√©sentation du texte

##### Bag of words
Vectorisation du vocabulaire par jeton et nombres d'occurences.

`hello world and hello universe` devient par exemple `[2, 1, 1, 1]` avec les jetons `{hello:0, world:1, and:2, universe:3}`.

Il s'agit des *raw terms frequencies* (tf) ou *n-gram*. 
N√©anmoins comme le nombre d'occurence d'un mot ne repr√©sente pas son importance, on utilise le *term frequency - inverse document frequency* (tf-idf) qui compare le *tf* par rapport au nombre de document contenant le terme.

Il existe plusieurs d√©clinaisons de *tf-idf*. Celui-ci est g√©n√©ralement normalis√©.

### Nettoyage du texte

Il faut g√©n√©ralement enlever les caract√®res sp√©ciaux, les majuscules, etc.

#### Stemming

Le stemming consiste √† supprimer les suffixes pour avoir en quelque sorte le radical (e.g. `running -> run`). 
N√©anmoins l'efficacit√© d√©pends de la langue.

#### Lemmatisation

Consiste √† retrouver les mots sous leur forme de base (e.g. `saw -> see`) en se basant sur un dictionnaire. 
Le probl√®me de cette m√©thode est qu'elle est tr√®s couteuse.

#### Retirer les stop words

Les stop words sont des "mots vide" qui n'apportent pas grand-chose (e.g. les d√©terminants)

## R√©gression

Se d√©marque de la classification car la r√©gression permet de pr√©dire des tendances en terme de variable continue, et d'expliquer la relation entre une variable et une caract√©ristique.

Le coefficient de d√©termination R¬≤ est la m√©thode la plus utilis√©e pour √©valuer les mod√®les de regression. 
Le R¬≤ est parfois √©gal √† la corr√©lation au carr√©.

### R√©gression lin√©aire

<img src="imgs/regression.png" width="400">

La distance entre les √©chantillons et la ligne repr√©sente l‚Äôerreur de pr√©diction.
Il existe plusieurs m√©thodes pour trouver la droite de tendance: ordinary least squares (minimise la distance verticale par rapport √† la droite au carr√©), random sample consensus (ransac, qui consiste √† utiliser un √©chantillon pour calculer le mod√®le), ...

Pour observer les relations lin√©aires entre les variables, on utilise une matrice de corr√©lation (Pearson's r).
Si *r* vaut 0, il n'y a aucune corr√©lation.

#### Remarques
La r√©gression lin√©aire est tr√®s sensible aux donn√©es aberrantes. On peut r√©duire l'impact selon la m√©thode employ√©e (e.g. ransac).

Il est facilement possible de tomber en surapprentissage, qui peut √™tre contr√©e par la r√©gularisation: 
* ridge regression (l2) : ajoute une p√©nalit√© selon la somme des poids aux carr√©s
* lasso (l1) : ajoute une p√©nalit√© selon la somme des poids en valeur absolue
* elastic net : hybride l1/l2

### R√©gression polynomiale

<img src="imgs/regression2.png" width="400">

Il s'agit de r√©aliser une regression de degr√© sup√©rieure, mais dans l'optique, cela reste un apprentissage de mod√®le lin√©aire.

Par exemple, pour un degr√© 2, si l'on pose `z = [x1, x2, x1x2, x1¬≤, x2¬≤]`, il s'agit d'une r√©gression linaire multiple en `z`.

### Regression trees

<img src="imgs/regression3.png" width="400">

Il s'agit d'arbre de d√©cision, mais dont la fonction d'impuret√© est calcul√© par le MSE (mean squared error).

## Deep learning

Il s'agit d'un ensemble d'algorithmes con√ßus pour l'entrainement sur plusieurs couches.
La backgpropagation est ce qui a majoritairement rendu cela possible.
Il s'agit g√©n√©ralement des m√©thodes state-of-the-art pour les probl√®mes √† donn√©es complexes (images, textes, voix).

Globalement pour faire du deep learning, il faut:
* Des fonctions diff√©rentiables et la backpropagation
* Des fonctions d'activation non lin√©aires
* Un optimiseur it√©ratif
* Beaucoup de donn√©es

### Perceptron multicouche

<img src="imgs/mlp.png" width="400">

Il s'agit d'une sorte de "perceptron" avec des couches cach√©es connect√©es de fa√ßon dense (en effet, contrairement au perceptron de base, les unit√©s sont continues et non binaires, et les activations sont sigmo√Ødales).
La couche de sortie est repr√©sent√© par un vecteur one-hot pour faire de la classification multiple.

La propagation avant permet de calculer la sortie du r√©seau.
Chaque couche sert d'entr√©e √† la couche suivante, sans qu'il n'y ait de boucle.

La fonction de co√ªts est la m√™me que logistic regression, mais g√©n√©ralis√©e √† toutes les unit√©s du r√©seau.
Il faut donc calculer la d√©riv√©e partielle de la matrice de poids par rapport √† tous les poids du r√©seau (sachant que les matrices n'ont pas forc√©ment la m√™me dimension).

#### Param√®tres particuliers

* *l2* permet de r√©duire le surapprentissage
* *alpha* permet d'ajouter un momentum au gradient de l'epoch pour acc√©lerer l'apprentissage
* *decrease* permet de r√©duire le learning rate au fil du temps

## Fonctions d'activation

Il existe deux familles : lin√©aire et non lin√©aire.

Sigmoid et tanh sont particuli√®rement adpat√© pour pr√©dire une probabilit√© comme sortie.
Elles sont d√©rivables et monotones. Tanh retourne des scores n√©gatif pour les entr√©es n√©gatives.

Relu (rectified linear unit) permet de d√©bloquer l'apprentissage si sigmoid et tanh ne marche pas.
Moins de probl√®me avec les gradient qui disparaissent (underflow), et les op√©rations sont plus simples (pas d'exponentielles).
Il existe des variantes comme le leaky relu.

<img src="imgs/activation.png" width="400">

## R√©seau de neurones √† convolutions (CNN)

Type particulier de r√©seau qui utilisent l'op√©ration de convolution plut√¥t que la multiplication matricielle.
Particuli√®rement adapat√© pour les donn√©es sous formes de grilles (images, sons, s√©quences).

La convolution prend une entr√©e et un kernel (filtre de convolution, souvent de taille impair) pour produire une sortie (feature map).

<img src="imgs/convolution.png" width="200">

Ce que l'on cherche √† apprendre sont les kernels, qui sont g√©n√©ralement assez petits.
En soit, plut√¥t que d'apprendre des poids diff√©rents pour chaque entr√©e, un seul ensemble de poids (celui du kernel) est appris.
Un autre avantage des convolutions est la connectivit√© locale ainsi que le fait de pouvoir travailler sur des entr√©es de tailles variables.

Les filtres (kernel) peuvent: 
* √™tre initialis√© de fa√ßon al√©atoire ou manuellement (edge detector, corner detector, ...)
* appris de fa√ßon supervis√© ou non supervis√© (via clustering et sur de petits morceaux d'images)

Le pooling permet d'essayer de rendre la repr√©sentation peu variable √† de petits changements (e.g. translation): Max pooling sur un petit voisinage, etc. Cela peut √©galement permettre de faire du downsampling, bien que ce soit possible directement avec la convolution (striding).Le pooling peut aussi permettre de garantir la taille d'une entr√©e si celle-ci est variable. N√©anmoins, il est possible de tomber dans le sous-apprentissage avec trop de pooling.

Une propri√©t√© int√©ressante des CNNs est qu'ils peuvent retourner un objet structur√© en haute dimension (e.g. la probabilit√© qu'un pixel appartienne √† une classe), ce qui permet de faire des masques pour la segmentation d'images.

<img src="imgs/seg.png" width="150">

Les CNNs peuvent facilement √™tre parall√©lis√© pour fonctionner sur GPU, et ils diminuent globalement le nombre d'op√©ration et l'utilisation de la m√©moire.

#### Architectures majeurs

Lenet, Alexnet, VGG, Inception/GoogleNet, Resnet.
